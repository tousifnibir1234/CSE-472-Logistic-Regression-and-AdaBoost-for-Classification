{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6458a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "np.random.seed(9999)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ba768",
   "metadata": {},
   "source": [
    "## Preprocessing of TElco Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30948173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\",na_values=[' ','?'])\n",
    "rowNum=df.shape[0]\n",
    "\n",
    "\n",
    "df.drop('customerID',inplace= True, axis=1)\n",
    "df['TotalCharges'].fillna(value=df['TotalCharges'].mean(),inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "##One hot encoding\n",
    "df = pd.get_dummies(df,drop_first=True) \n",
    "\n",
    "#standardize\n",
    "ss=StandardScaler()\n",
    "df.iloc[:,:]=ss.fit_transform(df.iloc[:,:])\n",
    "# df=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "dummyCol=np.ones(rowNum)#add a  1 column  to dataframe beginning\n",
    "df.insert(loc=0, column='dummy', value=dummyCol)\n",
    "\n",
    "dataset=df.copy()\n",
    "\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=99)\n",
    "df=train\n",
    "\n",
    "Y_out = df.iloc[:, -1]  #i final output\n",
    "Y_out = np.sign(Y_out)  #convert to -1 and +1\n",
    "df.drop(df.columns[-1], axis=1,inplace= True)  #drop the last column\n",
    "\n",
    "allCols=list(df.columns)\n",
    "coeff_df =pd.DataFrame(mutual_info_classif(df, Y_out).reshape(-1, 1),\n",
    "                         columns=['Coefficient'], index=feature_columns)\n",
    "col_names = coeff_df.sort_values(by='Coefficient', ascending=False)[:].index.values\n",
    "df = df.reindex(columns = col_names)\n",
    "\n",
    "# Dummy column full of ones at beginning of a matrix\n",
    "rowNum=df.shape[0]\n",
    "colNum= df.shape[1]\n",
    "print(rowNum, colNum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc27ce1",
   "metadata": {},
   "source": [
    "# Dataset 2 preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba62ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adult.data\",na_values = [\" \",' ?',np.NaN])\n",
    "rowNum=df.shape[0]\n",
    "\n",
    "df.columns=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\n",
    "                  \"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "obj=[]\n",
    "\n",
    "##StackOverflow\n",
    "catCols=df.select_dtypes(include=['object']).columns.tolist()\n",
    "for column in df:\n",
    "    if df[column].isnull().any():\n",
    "        if(column in catCols):\n",
    "            df[column]=df[column].fillna(df[column].mode()[0])\n",
    "        else:\n",
    "            df[column]=df[column].fillna(df[column].mean)\n",
    "    \n",
    "df = pd.get_dummies(df,drop_first=True) \n",
    "#standardize\n",
    "ss=StandardScaler()\n",
    "df.iloc[:,:]=ss.fit_transform(df.iloc[:,:])\n",
    "# df=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "dummyCol=np.ones(rowNum)#add a  1 column  to dataframe beginning\n",
    "df.insert(loc=0, column='dummy', value=dummyCol)\n",
    "\n",
    "dataset=df.copy()\n",
    "\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=99)\n",
    "df=train\n",
    "\n",
    "Y_out = df.iloc[:, -1]  #i final output\n",
    "Y_out = np.sign(Y_out)  #convert to -1 and +1\n",
    "df.drop(df.columns[-1], axis=1,inplace= True)  #drop the last column\n",
    "\n",
    "# Dummy column full of ones at beginning of a matrix\n",
    "rowNum=df.shape[0]\n",
    "colNum= df.shape[1]\n",
    "print(rowNum, colNum)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30509247",
   "metadata": {},
   "source": [
    "# ##Dataset 3 preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd6fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56962 31\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\",na_values = [\" \",' ?',np.NaN])\n",
    "rowNum=df.shape[0]\n",
    "\n",
    "catCols=df.select_dtypes(include=['object']).columns.tolist()\n",
    "for column in df:\n",
    "    if df[column].isnull().any():\n",
    "        if(column in catCols):\n",
    "            df[column]=df[column].fillna(df[column].mode()[0])\n",
    "        else:\n",
    "            df[column]=df[column].fillna(df[column].mean)\n",
    "    \n",
    "df = pd.get_dummies(df,drop_first=True) \n",
    "#standardize\n",
    "ss=StandardScaler()\n",
    "df.iloc[:,:]=ss.fit_transform(df.iloc[:,:])\n",
    "# df=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "dummyCol=np.ones(rowNum)#add a  1 column  to dataframe beginning\n",
    "df.insert(loc=0, column='dummy', value=dummyCol)\n",
    "\n",
    "dataset=df.copy()\n",
    "\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=99)\n",
    "df=test\n",
    "\n",
    "Y_out = df.iloc[:, -1]  #i final output\n",
    "Y_out = np.sign(Y_out)  #convert to -1 and +1\n",
    "df.drop(df.columns[-1], axis=1,inplace= True)  #drop the last column\n",
    "\n",
    "# Dummy column full of ones at beginning of a matrix\n",
    "rowNum=df.shape[0]\n",
    "colNum= df.shape[1]\n",
    "print(rowNum, colNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_out.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ac0886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dummy      Time        V1        V2        V3        V4        V5  \\\n",
      "172307    1.0  0.552394  1.137116 -0.472980 -0.761744 -0.607775 -0.616181   \n",
      "219008    1.0  0.984313 -0.205346 -0.238864  0.160666 -2.259042 -0.115314   \n",
      "27691     1.0 -1.266694 -0.263573  0.689220  0.776696 -0.218119  0.460646   \n",
      "14993     1.0 -1.442381  0.528477 -0.091407  0.860447  0.960069 -0.750376   \n",
      "198529    1.0  0.794245 -0.791530  0.952375  0.736865  2.103351  0.460811   \n",
      "\n",
      "              V6        V7        V8  ...       V20       V21       V22  \\\n",
      "172307 -1.055010 -0.414349 -0.260532  ... -0.172026  0.454356  1.271494   \n",
      "219008 -0.540939  0.315200 -0.017698  ... -0.279819 -0.304091 -0.675772   \n",
      "27691   0.067428  0.564557  0.008019  ...  0.212874 -0.303029 -0.716059   \n",
      "14993  -0.030630 -0.498035  0.167477  ... -0.078136  0.286327  0.895672   \n",
      "198529  1.516869  0.726627  0.634071  ... -0.573221  0.271092  0.831944   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28    Amount  \n",
      "172307  0.139635  0.087472  0.039468 -0.072022 -0.093634 -0.195622 -0.328241  \n",
      "219008  0.109905  1.086383 -0.163398 -0.938995  0.732208  0.577574 -0.105348  \n",
      "27691  -0.154901 -1.235942 -0.224703  0.281502  0.383776  0.328474 -0.342914  \n",
      "14993  -0.172113  0.928863  0.824906 -0.573317  0.138902  0.103854 -0.177314  \n",
      "198529 -0.684235 -1.700054  1.176973  0.792507 -0.593489 -0.261946  0.128980  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ab8c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "2646   1505   209   1274\n",
      "accuracy is  0.6957756478523252\n",
      "sensitivity is  0.8590694538098449\n",
      "specificity is  0.6374367622259697\n",
      "precision  0.45843828715365237\n",
      "fdr   0.5415617128463476\n",
      "f1 score  0.5978413890192398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-26.68      ,   7.585967  , -17.45672846,   9.71694101,\n",
       "        -9.8164052 ,  -0.46621448,  -7.9899716 ,  -8.00516181,\n",
       "         1.00251816,  -1.00251816,   2.03424738,  15.3285849 ,\n",
       "       -11.57659546, -11.57659546,  -8.58395802, -11.57659546,\n",
       "        -3.63655681, -11.57659546,  -3.77908358, -11.57659546,\n",
       "        -7.83718398, -11.57659546,   2.94905642, -11.57659546,\n",
       "         2.74846131,  -8.99942697, -15.03922262,   9.99224411,\n",
       "        -6.44928535,  15.30699415,  -4.64992708])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def logisticRegression(data,result):\n",
    "    checker=100000000\n",
    "    oneMatrix= np.ones(rowNum)\n",
    "#     weight=np.random.rand(colNum)\n",
    "    weight= np.zeros(colNum)\n",
    "    counter=0\n",
    "    while (checker >0.5  and counter<50000 ):\n",
    "        counter= counter +1\n",
    "        if(counter %10000 ==0) :\n",
    "            print(counter)\n",
    "        alpha = 0.01\n",
    "        tempDf= data.to_numpy()\n",
    "        Yp = np.tanh(tempDf.dot(weight))\n",
    "    #         Y = (df.iloc[:,-1]).to_numpy()\n",
    "        Y= result\n",
    "        M1 =1 - Yp **2\n",
    "#         print(M1)\n",
    "        M2= np.multiply( Y- Yp,M1)\n",
    "        M2 = alpha * M2\n",
    "        \n",
    "        transposedDf= tempDf.transpose()\n",
    "        r=transposedDf.dot(M2)\n",
    "#         weight= weight+ np.multiply(r,alpha)\n",
    "        weight = weight +r\n",
    "        checker = np.sum((Y-Yp)**2)/(2* rowNum)\n",
    "    print(checker)\n",
    "#     print(weight)\n",
    "\n",
    "    predicted= np.sign(np.tanh(tempDf.dot(weight)))\n",
    "    confusionFunctions(result,predicted)\n",
    "\n",
    "#     acc= accuracy_score(Y_out, predicted)\n",
    "#     print(\"accuracy value \" ,acc)\n",
    "#     print(weight)\n",
    "    return weight\n",
    "\n",
    "\n",
    "logisticRegression(df,Y_out)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563989e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.sign(Y_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c32e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f390f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "2544   1564   190   1336\n",
      "accuracy is  0.688675896343628\n",
      "sensitivity is  0.8754914809960681\n",
      "specificity is  0.6192794547224927\n",
      "precision  0.4606896551724138\n",
      "fdr   0.5393103448275862\n",
      "f1 score  0.6037053773158608\n",
      "0.5\n",
      "2616   1537   235   1246\n",
      "accuracy is  0.6854810081647142\n",
      "sensitivity is  0.8413234301147873\n",
      "specificity is  0.6299060919817\n",
      "precision  0.4477182896155228\n",
      "fdr   0.5522817103844772\n",
      "f1 score  0.5844277673545967\n",
      "0.5\n",
      "2647   1483   207   1297\n",
      "accuracy is  0.7000354987575435\n",
      "sensitivity is  0.8623670212765957\n",
      "specificity is  0.6409200968523002\n",
      "precision  0.46654676258992805\n",
      "fdr   0.5334532374100719\n",
      "f1 score  0.6055088702147525\n",
      "0.5\n",
      "2735   1486   207   1206\n",
      "accuracy is  0.6995030173943912\n",
      "sensitivity is  0.8535031847133758\n",
      "specificity is  0.6479507225775882\n",
      "precision  0.44799405646359586\n",
      "fdr   0.5520059435364042\n",
      "f1 score  0.5875761266747869\n",
      "0.5\n",
      "2761   1442   246   1185\n",
      "accuracy is  0.7003904863329783\n",
      "sensitivity is  0.8280922431865828\n",
      "specificity is  0.656911729716869\n",
      "precision  0.45108488770460603\n",
      "fdr   0.548915112295394\n",
      "f1 score  0.5840315426318383\n",
      "0.5\n",
      "2742   1457   222   1213\n",
      "accuracy is  0.7019879304224352\n",
      "sensitivity is  0.8452961672473868\n",
      "specificity is  0.6530126220528697\n",
      "precision  0.4543071161048689\n",
      "fdr   0.545692883895131\n",
      "f1 score  0.5909866017052375\n",
      "0.5\n",
      "2735   1478   255   1166\n",
      "accuracy is  0.692403265885694\n",
      "sensitivity is  0.8205489092188599\n",
      "specificity is  0.6491811061001661\n",
      "precision  0.4409984871406959\n",
      "fdr   0.5590015128593041\n",
      "f1 score  0.5736777367773678\n",
      "0.5\n",
      "2703   1452   232   1247\n",
      "accuracy is  0.7011004614838481\n",
      "sensitivity is  0.8431372549019608\n",
      "specificity is  0.6505415162454874\n",
      "precision  0.46202297147091514\n",
      "fdr   0.5379770285290848\n",
      "f1 score  0.5969363331737674\n",
      "0.5\n",
      "2809   1311   236   1278\n",
      "accuracy is  0.725417110401136\n",
      "sensitivity is  0.8441215323645971\n",
      "specificity is  0.6817961165048544\n",
      "precision  0.4936268829663963\n",
      "fdr   0.5063731170336037\n",
      "f1 score  0.6229588106263709\n",
      "0.5\n",
      "2924   1299   245   1166\n",
      "accuracy is  0.7259495917642883\n",
      "sensitivity is  0.8263642806520198\n",
      "specificity is  0.6923987686478806\n",
      "precision  0.4730223123732252\n",
      "fdr   0.5269776876267749\n",
      "f1 score  0.6016511867905057\n",
      "0.5\n",
      "2777   1377   259   1221\n",
      "accuracy is  0.7096201632942847\n",
      "sensitivity is  0.825\n",
      "specificity is  0.6685122773230621\n",
      "precision  0.46997690531177827\n",
      "fdr   0.5300230946882217\n",
      "f1 score  0.5988229524276606\n",
      "0.5\n",
      "2940   1293   236   1165\n",
      "accuracy is  0.7286119985800497\n",
      "sensitivity is  0.8315488936473947\n",
      "specificity is  0.6945428773919207\n",
      "precision  0.47396257119609436\n",
      "fdr   0.5260374288039056\n",
      "f1 score  0.6037833635656906\n",
      "0.5\n",
      "3017   1263   241   1113\n",
      "accuracy is  0.7330493432729854\n",
      "sensitivity is  0.8220088626292467\n",
      "specificity is  0.7049065420560747\n",
      "precision  0.4684343434343434\n",
      "fdr   0.5315656565656566\n",
      "f1 score  0.5967828418230563\n",
      "0.5\n",
      "3209   1109   308   1008\n",
      "accuracy is  0.7484913028044018\n",
      "sensitivity is  0.7659574468085106\n",
      "specificity is  0.7431681333950904\n",
      "precision  0.4761454888993859\n",
      "fdr   0.5238545111006141\n",
      "f1 score  0.587241479755316\n",
      "0.5\n",
      "3167   1115   303   1049\n",
      "accuracy is  0.7483138090166844\n",
      "sensitivity is  0.775887573964497\n",
      "specificity is  0.7396076599719758\n",
      "precision  0.48475046210720885\n",
      "fdr   0.5152495378927912\n",
      "f1 score  0.5967007963594995\n",
      "0.5\n",
      "3143   1076   360   1055\n",
      "accuracy is  0.7451189208377706\n",
      "sensitivity is  0.7455830388692579\n",
      "specificity is  0.7449632614363594\n",
      "precision  0.4950727358047865\n",
      "fdr   0.5049272641952135\n",
      "f1 score  0.5950366610265088\n",
      "0.5\n",
      "3142   1137   330   1025\n",
      "accuracy is  0.7396166134185304\n",
      "sensitivity is  0.7564575645756457\n",
      "specificity is  0.7342837111474644\n",
      "precision  0.47409805735430155\n",
      "fdr   0.5259019426456985\n",
      "f1 score  0.5828831390389536\n",
      "0.5\n",
      "3130   1129   295   1080\n",
      "accuracy is  0.7472488462903798\n",
      "sensitivity is  0.7854545454545454\n",
      "specificity is  0.7349142991312515\n",
      "precision  0.48890900860117703\n",
      "fdr   0.511090991398823\n",
      "f1 score  0.6026785714285714\n",
      "0.5\n",
      "3025   1171   355   1083\n",
      "accuracy is  0.729144479943202\n",
      "sensitivity is  0.7531293463143255\n",
      "specificity is  0.7209246901811249\n",
      "precision  0.48047914818101156\n",
      "fdr   0.5195208518189884\n",
      "f1 score  0.5866738894907909\n",
      "0.5\n",
      "2858   1109   424   1243\n",
      "accuracy is  0.72790202342918\n",
      "sensitivity is  0.7456508698260348\n",
      "specificity is  0.7204436601966221\n",
      "precision  0.5284863945578231\n",
      "fdr   0.47151360544217685\n",
      "f1 score  0.6185618313013187\n",
      "z is  [1.1454079  1.09654152 1.12942187 1.01879258 1.22844783 0.99307783\n",
      " 0.95350313 0.93384641 1.18768483 1.29169884 0.98982814 0.84807066\n",
      " 1.27193813 1.15989637 1.31259298 1.02021111 1.29485603 0.81108716\n",
      " 1.20542757 0.89665019]\n",
      "h shape is  (20, 31)\n",
      " data shape is  (31, 5634)\n",
      " m1 shape is  (20, 5634)\n",
      " p  is      5537  7042  1712  3072      4991  5919      5638      2356      3341  \\\n",
      "0   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.997469  1.000000   \n",
      "1   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.993553  1.000000   \n",
      "2   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.999999  1.000000   \n",
      "3   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.995344  1.000000   \n",
      "4   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.884764  1.000000   \n",
      "5   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.999915  1.000000   \n",
      "6   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  0.999999  1.000000   \n",
      "7   -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  1.000000  1.000000   \n",
      "8   -1.0  -1.0   1.0  -1.0  0.999998  -1.0 -1.000000  1.000000  1.000000   \n",
      "9   -1.0  -1.0   1.0  -1.0  0.999746  -1.0 -1.000000  1.000000  0.999884   \n",
      "10  -1.0  -1.0   1.0  -1.0  1.000000  -1.0 -1.000000  1.000000  1.000000   \n",
      "11  -1.0  -1.0   1.0  -1.0 -0.983249  -1.0 -1.000000  0.999998  1.000000   \n",
      "12  -1.0  -1.0   1.0  -1.0  0.955355  -1.0 -1.000000  0.994539  1.000000   \n",
      "13  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0 -1.000000 -1.000000  0.999988   \n",
      "14  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0 -1.000000 -0.886649  1.000000   \n",
      "15  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0  0.199943  0.997847  1.000000   \n",
      "16  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0  1.000000  0.868364  1.000000   \n",
      "17  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0 -1.000000 -0.999553  1.000000   \n",
      "18  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0  0.595355  1.000000  1.000000   \n",
      "19  -1.0  -1.0   1.0  -1.0 -1.000000  -1.0  1.000000  1.000000  1.000000   \n",
      "\n",
      "    969   ...  4081  55        3457  6068  5188  1768  1737  3240  5305  4737  \n",
      "0    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "1    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "2    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "3    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "4    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "5    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "6    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "7    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "8    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "9    1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "10   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "11   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "12   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "13   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "14   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "15   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "16   1.0  ...   1.0   1.0  1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "17   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "18   1.0  ...   1.0   1.0 -1.000000   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "19   1.0  ...   1.0   1.0 -0.711592   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  \n",
      "\n",
      "[20 rows x 5634 columns]\n",
      " P shape is  (20, 5634)\n",
      "  Z shape is  (20,)\n",
      " predict shape is  (5634,)\n",
      "2810   1341   247   1236\n",
      "accuracy is  0.7181398651047214\n",
      "sensitivity is  0.8334457181389077\n",
      "specificity is  0.6769453143820766\n",
      "precision  0.479627473806752\n",
      "fdr   0.5203725261932479\n",
      "f1 score  0.6088669950738916\n"
     ]
    }
   ],
   "source": [
    "def  WeightedMajority(h, z,data):\n",
    "    h= np.array(h)\n",
    "    z= np.array(z)\n",
    "    print('z is ', z)\n",
    "    print('h shape is ', h.shape)\n",
    "    data= data.transpose()\n",
    "    print(' data shape is ', data.shape)\n",
    "    M1= h@data\n",
    "    print(' m1 shape is ', M1.shape)\n",
    "    p=np.tanh(M1)\n",
    "    print(' p  is ',p)\n",
    "    print(' P shape is ', p.shape)\n",
    "    print ( '  Z shape is ',z.shape)\n",
    "    predict=z@p\n",
    "\n",
    "    print(' predict shape is ', predict.shape)\n",
    "    predict = np.sign(predict)\n",
    "    return predict\n",
    "\n",
    "# def  WeightedMajority(h, z,data):\n",
    "#     print('z is ',z)\n",
    "#     predict = np.zeros(len(data))\n",
    "#     for i in range(len(h)):\n",
    "#         predict= predict + z[i] * np.tanh(data.dot(h[i]))\n",
    "#     print('predict is', predict)\n",
    "#     predict= np.sign(predict)\n",
    "#     for i in predict: \n",
    "#         if ( i > 0):\n",
    "#             print('ok')\n",
    "#     print(predict)\n",
    "    \n",
    "def confusionFunctions (  yTrue ,yPredict):\n",
    "    tn, fp, fn, tp = confusion_matrix(yTrue,yPredict).ravel()\n",
    "    print(tn, \" \", fp, \" \",fn , \" \",tp)\n",
    "    accuracy = (tp+ tn)/(tp+fp+fn+tn)\n",
    "    print('accuracy is ',accuracy)\n",
    "    \n",
    "    \n",
    "    sensitivity = tp/(tp+fn)\n",
    "    print('sensitivity is ',sensitivity)\n",
    "    \n",
    "    specificity = tn/(tn+fp)\n",
    "    print('specificity is ',specificity)\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    print('precision ',precision)\n",
    "    \n",
    "    fdr = fp/(fp+tp)\n",
    "    print('fdr  ',fdr)\n",
    "    \n",
    "    f1_score=  2*tp/( 2*tp +fp + fn)\n",
    "    print('f1 score ',f1_score)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def adaboost(iteration):\n",
    "# print(df.iloc[0])\n",
    "    w=np.empty(rowNum)\n",
    "    w.fill(1/rowNum)\n",
    "    h=[]\n",
    "    z=[]\n",
    "    for k in range(iteration):\n",
    "        df['ans'] = Y_out\n",
    "\n",
    "        data =df.sample(n= len(df),replace= True, weights=w,random_state=97)\n",
    "        result = data['ans'].to_numpy()\n",
    "        \n",
    "        df.drop('ans',inplace= True, axis=1)\n",
    "        data.drop('ans',inplace= True, axis=1)\n",
    "        wL=logisticRegression(data,result)\n",
    "        predicted= np.sign(np.tanh((data.to_numpy()).dot(wL)))\n",
    "        \n",
    "        \n",
    "        error =0 \n",
    "        for j in range(len(data)):\n",
    "            if ( predicted[j] != result[j]) :\n",
    "                error = error + w[j]\n",
    "        if (error> 0.5 ):\n",
    "            continue \n",
    "        h.append(wL)\n",
    "\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            if( predicted[j] == result[j]):\n",
    "                w[j]=w[j] *(error)/(1-error)\n",
    "                \n",
    "        # Normalize W \n",
    "        s=np.sum(w)\n",
    "        w= w/s\n",
    "        # Finding z\n",
    "        q=math.log2((1-error)/error)\n",
    "#         print('q is ',q )\n",
    "        z.append(q)\n",
    "    predict= WeightedMajority(h,z,df)\n",
    "    confusionFunctions(Y_out,predict)\n",
    "\n",
    "        \n",
    "adaboost(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12575617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
